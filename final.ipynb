{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Relaxation for K-means Clustering - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Josipa Radnić, Tea Maričić, Lara Milić, Eleonora Detić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Matrična formulacija k sredina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo ćemo presložiti matricu podataka(**A**) na način da združimo one elemente koji pripadaju istom klasteru i napravimo od njih blokove. Nakon toga, pomoću kreiranih blokova, računamo broj elementa klastera(**$s_i$**) i nove centroide (**$m_i$**). Potom kreiramo matricu X pomoću jediničnih vektora i $s_i$ na način koji smo opisali na predavanjima. Na kraju, preostaje ponovo inverzno djelovati istom permutacijom na matricu $X$ kako bismo dobili $\\tilde{X}$ koja sadrži informacije o pripadnosti elementa početnoj particiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def matrix_formulation_Kmeans(A, D, k): #A is data matrix, D is list of correct clasters for columns of A, k is number of clasters\n",
    "    \n",
    "    new_A = np.empty([A.shape[0],0])\n",
    "    s_i = np.empty(k, dtype=int) \n",
    "    m_i = np.empty([A.shape[0],k])\n",
    "    permutation = np.empty(0,) \n",
    "\n",
    "    for i in range(k):\n",
    "        A_i = A[:, np.where(D == i)[1]] \n",
    "        permutation = np.append(permutation, np.where(D == i)[1], axis=0) \n",
    "        new_A = np.append(new_A, A_i, axis=1)\n",
    "        s_i[i] = np.where(D == i)[1].shape[0]\n",
    "        e = np.ones(s_i[i])\n",
    "        m_i[:,i] = (1/s_i[i]) * np.matmul(A_i, e) \n",
    "    \n",
    "    X = np.zeros([A.shape[1],k])\n",
    "\n",
    "    for i in range(k):\n",
    "        if( i == 0):\n",
    "            X[i:s_i[i], 0] = 1/s_i[1]\n",
    "        else:\n",
    "            X[ s_i[0:i].sum() : s_i[0:i].sum() + s_i[i], i] = 1/s_i[i-1]\n",
    "\n",
    "    X_tilde = np.zeros([A.shape[1],k])\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        index = list(permutation).index(i)  \n",
    "        X_tilde[int(permutation[i]), :] = X[i, :] \n",
    "\n",
    "    start_partition = np.empty(D.shape[1], dtype=int)\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        start_partition[i] = int(np.where(X_tilde[i, :] != 0)[0])\n",
    "    \n",
    "    start_partition = np.reshape(start_partition, (D.shape[1],1))\n",
    "    accuracy = accuracy_score(start_partition, np.transpose(D))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 K-means algoritam 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom poglavlju navodimo učinkovitu verziju k-means algoritma za klasteriranje koristeći metode linearne algebre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means_1(A_train, A_test, D_train, D_test, k): \n",
    "    #A_train and A_test are data matrix, D_train and D_test are arrays, k is number of clasters\n",
    "    \n",
    "    base_for_k_elements = dict()\n",
    "    \n",
    "    for i in range (k):\n",
    "        ii = [j for j, x in enumerate(D_train) if x == i] \n",
    "        B = A_train[:,ii]\n",
    "        U, S, V = np.linalg.svd(B)\n",
    "        base_for_k_elements[i] = U[:, 0:k]\n",
    "    \n",
    "    solution = np.zeros(len(D_test))\n",
    "    \n",
    "    for i in range (len(D_test)):\n",
    "        min_distance = np.inf \n",
    "        claster = 0\n",
    "        for j in range (0,k):\n",
    "            distance = np.linalg.norm(A_test[:,i] - np.dot(np.dot(base_for_k_elements[j], base_for_k_elements[j].T),A_test[:,i]))\n",
    "            if (distance < min_distance):\n",
    "                min_distance = distance\n",
    "                claster = j \n",
    "        solution[i] = claster\n",
    "    \n",
    "    return accuracy_score(solution, D_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 K-means algoritam 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom poglavlju navodimo jednostavnu, standardnu verziju k-means algoritma koja klasterira podatke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means_2(A, starting_partition, k, epsilon): \n",
    "    #A is data frame, one data is one present as one column\n",
    "    #starting_partition is starting partition, usually random\n",
    "    #k is number of clasters\n",
    "    #epsilon is small number, stop criterion\n",
    "    \n",
    "\n",
    "    A.columns = starting_partition\n",
    "    partition = starting_partition\n",
    "\n",
    "    number_of_iteration = 0\n",
    "    Q_of_partition = np.inf\n",
    "\n",
    "    while(Q_of_partition > epsilon):\n",
    "    \n",
    "        number_of_iteration += 1\n",
    "\n",
    "        s_i = np.unique(partition, axis=0, return_counts=True)[1]\n",
    "        a_i = A.groupby(level=0,axis=1).sum().add_suffix('. centroid')\n",
    "        m_i = a_i / s_i \n",
    "    \n",
    "        Q_of_partition_before = 0\n",
    "        for i in range(A.shape[1]):\n",
    "            Q_of_partition_before  += np.linalg.norm((A.iloc[:,i] - m_i.iloc[:,A.columns[i]]))\n",
    "        \n",
    "        \n",
    "        for i in range(A.shape[1]): \n",
    "            distance_final = np.inf\n",
    "            for j in range(0, m_i.shape[1]):\n",
    "                distance = np.linalg.norm((A.iloc[:,i] - m_i.iloc[:,j]))\n",
    "                if(distance < distance_final):\n",
    "                    distance_final = distance\n",
    "                    tmp = list(A.columns)\n",
    "                    tmp[i] = j\n",
    "                    A.columns = tmp \n",
    "                \n",
    "        partition = A.columns.values\n",
    "    \n",
    "        Q_of_partition_after = 0\n",
    "        for i in range(A.shape[1]):\n",
    "            Q_of_partition_after  += np.linalg.norm((A.iloc[:,i] - m_i.iloc[:,A.columns[i]]))\n",
    "    \n",
    "        Q_of_partition = Q_of_partition_before - Q_of_partition_after\n",
    "\n",
    "    return number_of_iteration, m_i, A.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Spektralna relaksacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koristeći spektralnu relaksaciju, cilj je smanjiti  dimenzije matrice A, ali svejedno očuvati sve potrebne informacije. Koristeći rezulate članka, vidimo da je dovoljno uzeti samo prvih k svojstvenih vektora koji odgovaraju k najvećim svojstvenim vrijednostima. Na taj način formiramo matricu X_k na čije retke primjenjujemo k-means. Svaki podatak više nije $m \\times 1$, već $k \\times 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eigh\n",
    "import numpy as np\n",
    "\n",
    "def spectral_relaxation(A):\n",
    "    #A is data matrix\n",
    "\n",
    "    eigenvalues, eigenvectors = eigh(np.transpose(A) @ A) \n",
    "    \n",
    "    eigenvalues = eigenvalues[A.shape[1]-k:A.shape[1]][::-1] \n",
    "    X_k = np.flip(eigenvectors[:, (A.shape[1]-k):A.shape[1]] ,axis=1)\n",
    "    \n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 QR faktorizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daljni pokušaji poboljšanja k-means algoritma tiču se početne particije. Naime, voljeli bismo nekako dobiti najbolju moguću početnu particiju. Prije je bila ona bila random, sada bismo je voljeli nekako specificirati i reći da imamo najbolju moguću. Šta god \"najbolje moguće\" značilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_for_starting_partition(A):\n",
    "    #A is data matrix\n",
    "    \n",
    "    X_k = spectral_relaxation(A)\n",
    "\n",
    "    Q, R, P = scipy.linalg.qr(np.transpose(X_k), pivoting = True)\n",
    "    P_ = np.zeros([A.shape[1],A.shape[1]])\n",
    "    for i in range(A.shape[1]):\n",
    "        P_[i,P[i]] = 1\n",
    "\n",
    "    R_11 = R[0:k, 0:k]\n",
    "    R_12 = R[0:k, k:R.shape[1]]\n",
    "    I = np.eye(k, dtype=int)\n",
    "    R = np.matmul(np.linalg.inv(R_11), R_12)\n",
    "\n",
    "    R_kapa = np.append(I,R,axis=1)  @  np.transpose(P_)\n",
    "    R_kapa = np.absolute(R_kapa)\n",
    "    \n",
    "    return np.argmax(R_kapa, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 1 K-means koristeći spektralnu relaksaciju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_K_means(A,k,epsilon):\n",
    "    \n",
    "    X_k = spectral_relaxation(A)\n",
    "    X_k = np.transpose(X_k)\n",
    "    \n",
    "    while True: \n",
    "        starting_partition = np.random.randint(0, k, A.shape[1])\n",
    "        s_i = np.unique(starting_partition, axis=0, return_counts=True)[1]\n",
    "        if len(s_i) == k:\n",
    "            break\n",
    "    \n",
    "    return K_means_2(pd.DataFrame(X_k), starting_partition, k, epsilon)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 K-means koristeći QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_QR(A,k,epsilon):\n",
    "    \n",
    "    X_k = spectral_relaxation(A)\n",
    "    X_k = np.transpose(X_k)\n",
    "    \n",
    "    starting_partition = QR_for_starting_partition(A)\n",
    "    \n",
    "    return K_means_2(pd.DataFrame(X_k), starting_partition, k, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 K-means for predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Podaci - znamenke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat_1 = scipy.io.loadmat('azip.mat')\n",
    "A_digits = mat_1['azip'] \n",
    "\n",
    "mat_2 = scipy.io.loadmat('dzip.mat')\n",
    "D_digits = mat_2['dzip']\n",
    "\n",
    "k_digits = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Podaci - pacijenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Podaci - odjevni predmeti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Podaci - točke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Usporedba rezultata, zaključci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeb592eeb14baf80ba7e3ad598b9cc718d92fa62785d72005ca19f7c0e0c833d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
